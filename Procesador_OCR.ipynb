{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlejandroBeltre/AlejandroBeltre/blob/main/Procesador_OCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Celda #1: Instalación de dependencias y configuración de entorno**"
      ],
      "metadata": {
        "id": "HUSLrMze4Lkh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JRzxGE6LRppI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "158c8774-cec2-49b0-f5e7-d6262d294322",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurando entorno OCR para alto rendimiento...\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "\n",
            "Configurando Tesseract correctamente...\n",
            "   Tessdata encontrado en: /usr/share/tesseract-ocr/4.00/tessdata/\n",
            "   Archivos de idioma disponibles: 3\n",
            "   Español (spa): Disponible\n",
            "   Inglés (eng): Disponible\n",
            "\n",
            "Variables de entorno configuradas:\n",
            "   TESSDATA_PREFIX: /usr/share/tesseract-ocr/4.00/tessdata/\n",
            "   OMP_THREAD_LIMIT: 2\n",
            "\n",
            "Entorno OCR configurado exitosamente\n"
          ]
        }
      ],
      "source": [
        "print(\"Configurando entorno OCR para alto rendimiento...\")\n",
        "\n",
        "# Actualizar sistema\n",
        "!apt-get update -qq\n",
        "\n",
        "# Instalar dependencias del sistema con todos los idiomas necesarios\n",
        "!apt-get install -y poppler-utils tesseract-ocr tesseract-ocr-spa tesseract-ocr-eng -qq\n",
        "\n",
        "# Instalar paquetes Python necesarios\n",
        "!pip install pdf2image pytesseract psutil gspread google-auth-oauthlib google-auth-httplib2 google-api-python-client -q\n",
        "\n",
        "# Actualizar pillow si es necesario\n",
        "!pip install --upgrade pillow -q\n",
        "\n",
        "print(\"\\nConfigurando Tesseract correctamente...\")\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Auto-detección y configuración de TESSDATA_PREFIX\n",
        "def configurar_tesseract():\n",
        "    \"\"\"Detecta y configura automáticamente la ruta de Tesseract\"\"\"\n",
        "    possible_paths = [\n",
        "        '/usr/share/tesseract-ocr/4.00/tessdata/',\n",
        "        '/usr/share/tesseract-ocr/5/tessdata/',\n",
        "        '/usr/share/tessdata/',\n",
        "        '/usr/local/share/tessdata/'\n",
        "    ]\n",
        "\n",
        "    tessdata_path = None\n",
        "    for path in possible_paths:\n",
        "        if os.path.exists(path):\n",
        "            files = glob.glob(f\"{path}*.traineddata\")\n",
        "            if files:\n",
        "                tessdata_path = path\n",
        "                print(f\"   Tessdata encontrado en: {path}\")\n",
        "                print(f\"   Archivos de idioma disponibles: {len(files)}\")\n",
        "\n",
        "                # Verificar que tenemos español\n",
        "                spa_file = f\"{path}spa.traineddata\"\n",
        "                eng_file = f\"{path}eng.traineddata\"\n",
        "\n",
        "                if os.path.exists(spa_file):\n",
        "                    print(\"   Español (spa): Disponible\")\n",
        "                else:\n",
        "                    print(\"   Español (spa): No encontrado\")\n",
        "\n",
        "                if os.path.exists(eng_file):\n",
        "                    print(\"   Inglés (eng): Disponible\")\n",
        "                else:\n",
        "                    print(\"   Inglés (eng): No encontrado\")\n",
        "\n",
        "                break\n",
        "\n",
        "    if not tessdata_path:\n",
        "        print(\"   No se encontraron archivos de datos, descargando...\")\n",
        "        tessdata_path = '/usr/share/tessdata/'\n",
        "        os.makedirs(tessdata_path, exist_ok=True)\n",
        "\n",
        "        # Descargar archivos de datos si no existen\n",
        "        if not os.path.exists(f\"{tessdata_path}spa.traineddata\"):\n",
        "            print(\"   Descargando datos de español...\")\n",
        "            !wget -q https://github.com/tesseract-ocr/tessdata/raw/main/spa.traineddata -O /usr/share/tessdata/spa.traineddata\n",
        "\n",
        "        if not os.path.exists(f\"{tessdata_path}eng.traineddata\"):\n",
        "            print(\"   Descargando datos de inglés...\")\n",
        "            !wget -q https://github.com/tesseract-ocr/tessdata/raw/main/eng.traineddata -O /usr/share/tessdata/eng.traineddata\n",
        "\n",
        "    return tessdata_path\n",
        "\n",
        "# Configurar Tesseract\n",
        "tessdata_path = configurar_tesseract()\n",
        "\n",
        "# Configurar variables de entorno\n",
        "os.environ['TESSDATA_PREFIX'] = tessdata_path\n",
        "os.environ['OMP_THREAD_LIMIT'] = '2'\n",
        "\n",
        "print(f\"\\nVariables de entorno configuradas:\")\n",
        "print(f\"   TESSDATA_PREFIX: {os.environ.get('TESSDATA_PREFIX')}\")\n",
        "print(f\"   OMP_THREAD_LIMIT: {os.environ.get('OMP_THREAD_LIMIT')}\")\n",
        "\n",
        "print(\"\\nEntorno OCR configurado exitosamente\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Celda #2: Importaciones, clases de datos y optimizador**"
      ],
      "metadata": {
        "id": "zI2OWASO-_lU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import gc\n",
        "import psutil\n",
        "import time\n",
        "from typing import List, Optional, Tuple, Dict\n",
        "from dataclasses import dataclass, field\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import multiprocessing as mp\n",
        "from PIL import Image\n",
        "import threading\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "@dataclass\n",
        "class DetalleProducto:\n",
        "    \"\"\"Producto individual en la factura\"\"\"\n",
        "    ncf_factura_fk: str = \"\"\n",
        "    pos: int = 0\n",
        "    item_codigo: str = \"\"\n",
        "    descripcion: str = \"\"\n",
        "    cantidad: int = 1\n",
        "    precio_unitario: float = 0.0\n",
        "    total_linea_con_itbis: float = 0.0\n",
        "\n",
        "@dataclass\n",
        "class FacturaPrincipal:\n",
        "    \"\"\"Estructura de factura\"\"\"\n",
        "    ncf_factura: str = \"No encontrado\"\n",
        "    cliente_rnc: str = \"No encontrado\"\n",
        "    cliente_nombre: str = \"No encontrado\"\n",
        "    fecha_emision: str = \"No encontrado\"\n",
        "    fecha_vencimiento: str = \"No encontrado\"\n",
        "    tipo_pago: str = \"No encontrado\"\n",
        "    valor_pagar: float = 0.0\n",
        "    vendedor: str = \"No encontrado\"\n",
        "    nombre_archivo: str = \"\"\n",
        "    link_archivo_drive: str = \"\"\n",
        "\n",
        "@dataclass\n",
        "class MetadataProceso:\n",
        "    \"\"\"Metadatos del procesamiento\"\"\"\n",
        "    nombre_archivo: str\n",
        "    link_archivo_drive: str\n",
        "    timestamp_proceso: str = field(default_factory=lambda: datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
        "    estado_ocr: str = \"Iniciado\"\n",
        "    error: str = \"\"\n",
        "    campos_extraidos: int = 0\n",
        "    confianza_extraccion: str = \"Baja\"\n",
        "    tiempo_procesamiento: float = 0.0\n",
        "\n",
        "class PatternExtractor:\n",
        "    \"\"\"Extractor de patrones con compilación para rendimiento\"\"\"\n",
        "\n",
        "    _COMPILED_PATTERNS = None\n",
        "\n",
        "    @classmethod\n",
        "    def _get_compiled_patterns(cls):\n",
        "        \"\"\"Lazy loading de patrones compilados\"\"\"\n",
        "        if cls._COMPILED_PATTERNS is None:\n",
        "            cls._COMPILED_PATTERNS = {\n",
        "                'ncf': [\n",
        "                    re.compile(r'(E31\\d{10})'),\n",
        "                    re.compile(r'(ES1\\d{10})'),\n",
        "                    re.compile(r'(E5l\\d{10})'),\n",
        "                    re.compile(r'(ESl\\d{10})'),\n",
        "                    re.compile(r'(E3l\\d{10})'),\n",
        "                    re.compile(r'(ESI\\d{10})'),\n",
        "                    re.compile(r'(E3I\\d{10})'),\n",
        "                ],\n",
        "                'rnc': [\n",
        "                    re.compile(r'RNC Cliente\\s*:\\s*([0-9\\-]+)'),\n",
        "                    re.compile(r'RNC.*?(\\d{8,12})'),\n",
        "                    re.compile(r'Cliente\\s*:\\s*([0-9\\-]+)'),\n",
        "                ],\n",
        "                'fecha_emision': [\n",
        "                    re.compile(r'FECHA FACTURA\\s*:\\s*(\\d{2}\\.\\d{2}\\.\\d{4})'),\n",
        "                    re.compile(r'FECHA.*?(\\d{2}\\.\\d{2}\\.\\d{4})'),\n",
        "                ],\n",
        "                'tipo_pago': [\n",
        "                    re.compile(r'(CREDITO|CONTADO)', re.IGNORECASE),\n",
        "                ],\n",
        "                'valor_pagar': [\n",
        "                    re.compile(r'VALOR A PAGAR\\s*\\$?\\s*([0-9]{1,3}(?:\\.[0-9]{3})*,\\d{2})'),\n",
        "                    re.compile(r'Total a Pagar\\s*\\$?\\s*([0-9]{1,3}(?:\\.[0-9]{3})*,\\d{2})'),\n",
        "                    re.compile(r'PAGAR\\s*\\$\\s*([0-9]{1,3}(?:\\.[0-9]{3})*,\\d{2})'),\n",
        "                ],\n",
        "                'nombre_cliente': [\n",
        "                    re.compile(r'Razón Social\\s*:\\s*(.*?)(?:\\s*Establecimiento|\\s*$)'),\n",
        "                ],\n",
        "                'vendedor': [\n",
        "                    re.compile(r'Vendedor\\s*:\\s*([A-Z\\s]+?)(?:\\s*Entrega|\\s*$)'),\n",
        "                ]\n",
        "            }\n",
        "        return cls._COMPILED_PATTERNS\n",
        "\n",
        "    @staticmethod\n",
        "    def extraer_campo(texto: str, campo: str) -> Optional[str]:\n",
        "        \"\"\"Extracción usando patrones compilados\"\"\"\n",
        "        patterns = PatternExtractor._get_compiled_patterns().get(campo, [])\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = pattern.search(texto)\n",
        "            if match:\n",
        "                resultado = match.group(1).strip()\n",
        "\n",
        "                if campo == 'ncf':\n",
        "                    resultado = PatternExtractor._corregir_ncf(resultado)\n",
        "                elif campo == 'tipo_pago':\n",
        "                    resultado = resultado.upper()\n",
        "\n",
        "                return resultado\n",
        "        return None\n",
        "\n",
        "    @staticmethod\n",
        "    def _corregir_ncf(ncf: str) -> str:\n",
        "        \"\"\"Corrección de NCF con mapeo directo\"\"\"\n",
        "        correcciones = {\n",
        "            'ES1': 'E31', 'E5l': 'E31', 'ESl': 'E31',\n",
        "            'E3l': 'E31', 'ESI': 'E31', 'E3I': 'E31'\n",
        "        }\n",
        "        prefijo = ncf[:3] if len(ncf) >= 3 else ncf\n",
        "        return correcciones.get(prefijo, prefijo) + ncf[3:] if prefijo in correcciones else ncf\n",
        "\n",
        "class ValueNormalizer:\n",
        "    \"\"\"Normalización de valores monetarios dominicanos\"\"\"\n",
        "\n",
        "    _MONEY_PATTERN = re.compile(r'^([0-9]{1,3}(?:\\.[0-9]{3})*),(\\d{1,2})$')\n",
        "    _CLEAN_PATTERN = re.compile(r'[^\\d.,]')\n",
        "\n",
        "    @staticmethod\n",
        "    def normalizar_valor_monetario(valor_str: str) -> float:\n",
        "        \"\"\"Normalización para formato dominicano (ejemplo: \"28.164,72\" -> 28164.72)\"\"\"\n",
        "        if not valor_str or not valor_str.strip():\n",
        "            return 0.0\n",
        "\n",
        "        try:\n",
        "            valor_limpio = ValueNormalizer._CLEAN_PATTERN.sub('', valor_str.strip())\n",
        "\n",
        "            if ',' in valor_limpio:\n",
        "                match = ValueNormalizer._MONEY_PATTERN.match(valor_limpio)\n",
        "                if match:\n",
        "                    parte_entera = match.group(1).replace('.', '')\n",
        "                    parte_decimal = match.group(2).ljust(2, '0')[:2]\n",
        "                    return float(f\"{parte_entera}.{parte_decimal}\")\n",
        "                else:\n",
        "                    partes = valor_limpio.split(',')\n",
        "                    if len(partes) == 2:\n",
        "                        parte_entera = partes[0].replace('.', '')\n",
        "                        parte_decimal = partes[1][:2].ljust(2, '0')\n",
        "                        return float(f\"{parte_entera}.{parte_decimal}\")\n",
        "            else:\n",
        "                return float(valor_limpio.replace('.', ''))\n",
        "\n",
        "        except (ValueError, AttributeError):\n",
        "            return 0.0\n",
        "\n",
        "        return 0.0\n",
        "\n",
        "class OCRProcessor:\n",
        "    \"\"\"Procesador OCR con configuración de alto rendimiento\"\"\"\n",
        "\n",
        "    FAST_CONFIG = '--psm 6 --oem 3 -c preserve_interword_spaces=1'\n",
        "\n",
        "    @staticmethod\n",
        "    def verificar_configuracion_tesseract():\n",
        "        \"\"\"Verifica que Tesseract esté configurado correctamente\"\"\"\n",
        "        import os\n",
        "        tessdata_prefix = os.environ.get('TESSDATA_PREFIX', '')\n",
        "\n",
        "        if not tessdata_prefix:\n",
        "            print(\"TESSDATA_PREFIX no configurado, aplicando auto-detección...\")\n",
        "\n",
        "            # Auto-detección de tessdata\n",
        "            import glob\n",
        "            possible_paths = [\n",
        "                '/usr/share/tesseract-ocr/4.00/tessdata/',\n",
        "                '/usr/share/tesseract-ocr/5/tessdata/',\n",
        "                '/usr/share/tessdata/',\n",
        "                '/usr/local/share/tessdata/'\n",
        "            ]\n",
        "\n",
        "            for path in possible_paths:\n",
        "                if os.path.exists(path) and glob.glob(f\"{path}*.traineddata\"):\n",
        "                    os.environ['TESSDATA_PREFIX'] = path\n",
        "                    print(f\"TESSDATA_PREFIX configurado automáticamente: {path}\")\n",
        "                    break\n",
        "\n",
        "    @staticmethod\n",
        "    def test_ocr_simple() -> bool:\n",
        "        \"\"\"Prueba básica de OCR para diagnóstico\"\"\"\n",
        "        try:\n",
        "            # Verificar configuración antes del test\n",
        "            OCRProcessor.verificar_configuracion_tesseract()\n",
        "\n",
        "            from PIL import Image, ImageDraw\n",
        "            img = Image.new('RGB', (300, 150), color='white')\n",
        "            draw = ImageDraw.Draw(img)\n",
        "            draw.text((20, 50), \"FACTURA TEST 123\", fill='black')\n",
        "            draw.text((20, 80), \"NCF: E31000001234\", fill='black')\n",
        "\n",
        "            # Probar con español primero\n",
        "            try:\n",
        "                result_spa = pytesseract.image_to_string(img, lang='spa', config=OCRProcessor.FAST_CONFIG)\n",
        "                if \"FACTURA\" in result_spa or \"TEST\" in result_spa or \"E31\" in result_spa:\n",
        "                    return True\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            # Fallback a inglés\n",
        "            try:\n",
        "                result_eng = pytesseract.image_to_string(img, lang='eng', config=OCRProcessor.FAST_CONFIG)\n",
        "                if \"FACTURA\" in result_eng or \"TEST\" in result_eng or \"E31\" in result_eng:\n",
        "                    return True\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            return False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Test OCR falló: {e}\")\n",
        "            return False\n",
        "\n",
        "    @staticmethod\n",
        "    def extraer_texto_con_diagnostico(imagen: Image.Image, timeout: int = 30) -> Tuple[str, str]:\n",
        "        \"\"\"Extracción con diagnóstico detallado y fallback de idiomas\"\"\"\n",
        "        diagnostico = \"\"\n",
        "\n",
        "        try:\n",
        "            # Verificar configuración primero\n",
        "            OCRProcessor.verificar_configuracion_tesseract()\n",
        "\n",
        "            if imagen is None:\n",
        "                return \"\", \"Imagen es None\"\n",
        "\n",
        "            if imagen.size[0] == 0 or imagen.size[1] == 0:\n",
        "                return \"\", f\"Imagen tiene tamaño inválido: {imagen.size}\"\n",
        "\n",
        "            diagnostico += f\"Imagen OK: {imagen.size[0]}x{imagen.size[1]} \"\n",
        "\n",
        "            # Intentar con español primero (mejor para facturas dominicanas)\n",
        "            try:\n",
        "                texto = pytesseract.image_to_string(\n",
        "                    imagen,\n",
        "                    lang='spa',\n",
        "                    config=OCRProcessor.FAST_CONFIG,\n",
        "                    timeout=timeout\n",
        "                )\n",
        "\n",
        "                if texto and texto.strip():\n",
        "                    diagnostico += f\"OCR español exitoso: {len(texto)} caracteres\"\n",
        "                    return texto, diagnostico\n",
        "                else:\n",
        "                    diagnostico += \"OCR español: texto vacío, probando inglés... \"\n",
        "            except Exception as e:\n",
        "                diagnostico += f\"OCR español falló: {str(e)[:50]}, probando inglés... \"\n",
        "\n",
        "            # Fallback a inglés\n",
        "            try:\n",
        "                texto = pytesseract.image_to_string(\n",
        "                    imagen,\n",
        "                    lang='eng',\n",
        "                    config=OCRProcessor.FAST_CONFIG,\n",
        "                    timeout=timeout\n",
        "                )\n",
        "\n",
        "                if texto and texto.strip():\n",
        "                    diagnostico += f\"OCR inglés exitoso: {len(texto)} caracteres\"\n",
        "                    return texto, diagnostico\n",
        "                else:\n",
        "                    diagnostico += \"OCR inglés: texto vacío\"\n",
        "                    return \"\", diagnostico\n",
        "\n",
        "            except Exception as e:\n",
        "                diagnostico += f\"OCR inglés falló: {str(e)}\"\n",
        "                return \"\", diagnostico\n",
        "\n",
        "        except Exception as e:\n",
        "            diagnostico += f\"Error crítico OCR: {str(e)}\"\n",
        "            return \"\", diagnostico\n",
        "\n",
        "    @staticmethod\n",
        "    def procesar_pdf_con_diagnostico(ruta_pdf: str, dpi: int = 200) -> Tuple[str, List[str]]:\n",
        "        \"\"\"Procesamiento PDF con diagnóstico completo\"\"\"\n",
        "        diagnosticos = []\n",
        "\n",
        "        try:\n",
        "            if not os.path.exists(ruta_pdf):\n",
        "                diagnosticos.append(f\"Archivo no existe: {ruta_pdf}\")\n",
        "                return \"\", diagnosticos\n",
        "\n",
        "            file_size = os.path.getsize(ruta_pdf)\n",
        "            if file_size == 0:\n",
        "                diagnosticos.append(f\"Archivo vacío: {ruta_pdf}\")\n",
        "                return \"\", diagnosticos\n",
        "\n",
        "            diagnosticos.append(f\"Archivo OK: {file_size} bytes\")\n",
        "\n",
        "            try:\n",
        "                imagenes = convert_from_path(ruta_pdf, dpi=dpi)\n",
        "                diagnosticos.append(f\"Conversión exitosa: {len(imagenes)} página(s)\")\n",
        "            except Exception as e:\n",
        "                diagnosticos.append(f\"Error conversión PDF: {str(e)}\")\n",
        "                return \"\", diagnosticos\n",
        "\n",
        "            if not imagenes:\n",
        "                diagnosticos.append(\"No se generaron imágenes del PDF\")\n",
        "                return \"\", diagnosticos\n",
        "\n",
        "            textos_paginas = []\n",
        "            for i, imagen in enumerate(imagenes):\n",
        "                texto_pagina, diag_pagina = OCRProcessor.extraer_texto_con_diagnostico(imagen)\n",
        "                diagnosticos.append(f\"Página {i+1}: {diag_pagina}\")\n",
        "\n",
        "                if texto_pagina and texto_pagina.strip():\n",
        "                    textos_paginas.append(texto_pagina)\n",
        "\n",
        "                del imagen\n",
        "\n",
        "            texto_completo = ' '.join(textos_paginas)\n",
        "\n",
        "            if texto_completo.strip():\n",
        "                diagnosticos.append(f\"Texto extraído: {len(texto_completo)} caracteres total\")\n",
        "                return texto_completo, diagnosticos\n",
        "            else:\n",
        "                diagnosticos.append(\"No se extrajo texto de ninguna página\")\n",
        "                return \"\", diagnosticos\n",
        "\n",
        "        except Exception as e:\n",
        "            diagnosticos.append(f\"Error crítico: {str(e)}\")\n",
        "            return \"\", diagnosticos\n",
        "\n",
        "class BatchSheetsManager:\n",
        "    \"\"\"Manejo por lotes de Google Sheets para reducir latencia\"\"\"\n",
        "\n",
        "    def __init__(self, spreadsheet):\n",
        "        self.spreadsheet = spreadsheet\n",
        "        self._facturas_batch = []\n",
        "        self._metadata_batch = []\n",
        "        self._batch_size = 50\n",
        "\n",
        "    def add_factura(self, factura_data: List):\n",
        "        \"\"\"Añade factura al lote\"\"\"\n",
        "        self._facturas_batch.append(factura_data)\n",
        "\n",
        "    def add_metadata(self, metadata_data: List):\n",
        "        \"\"\"Añade metadata al lote\"\"\"\n",
        "        self._metadata_batch.append(metadata_data)\n",
        "\n",
        "    def flush_batch(self):\n",
        "        \"\"\"Envía lote completo a Google Sheets\"\"\"\n",
        "        try:\n",
        "            if self._facturas_batch:\n",
        "                facturas_sheet = self.spreadsheet.worksheet(\"Facturas_Digitalizadas\")\n",
        "                facturas_sheet.append_rows(self._facturas_batch, value_input_option='USER_ENTERED')\n",
        "                print(f\"Lote enviado: {len(self._facturas_batch)} facturas\")\n",
        "                self._facturas_batch.clear()\n",
        "\n",
        "            if self._metadata_batch:\n",
        "                metadata_sheet = self.spreadsheet.worksheet(\"Metadata\")\n",
        "                metadata_sheet.append_rows(self._metadata_batch, value_input_option='USER_ENTERED')\n",
        "                print(f\"Lote enviado: {len(self._metadata_batch)} metadata\")\n",
        "                self._metadata_batch.clear()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error enviando lote: {e}\")\n",
        "\n",
        "    def should_flush(self) -> bool:\n",
        "        \"\"\"Verifica si debe enviar el lote\"\"\"\n",
        "        return (len(self._facturas_batch) >= self._batch_size or\n",
        "                len(self._metadata_batch) >= self._batch_size)\n",
        "\n",
        "class PerformanceMonitor:\n",
        "    \"\"\"Monitor de rendimiento\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset_stats()\n",
        "\n",
        "    def reset_stats(self):\n",
        "        self.stats = {\n",
        "            'total_archivos': 0,\n",
        "            'exitosos': 0,\n",
        "            'fallidos': 0,\n",
        "            'tiempo_total': 0.0,\n",
        "            'tiempo_promedio': 0.0,\n",
        "            'archivos_por_minuto': 0.0,\n",
        "            'memoria_maxima': 0.0\n",
        "        }\n",
        "\n",
        "    def record_file_processed(self, tiempo_archivo: float, exitoso: bool):\n",
        "        \"\"\"Registra estadísticas de archivo procesado\"\"\"\n",
        "        self.stats['total_archivos'] += 1\n",
        "        self.stats['tiempo_total'] += tiempo_archivo\n",
        "\n",
        "        if exitoso:\n",
        "            self.stats['exitosos'] += 1\n",
        "        else:\n",
        "            self.stats['fallidos'] += 1\n",
        "\n",
        "        if self.stats['total_archivos'] > 0:\n",
        "            self.stats['tiempo_promedio'] = self.stats['tiempo_total'] / self.stats['total_archivos']\n",
        "            self.stats['archivos_por_minuto'] = 60.0 / self.stats['tiempo_promedio'] if self.stats['tiempo_promedio'] > 0 else 0\n",
        "\n",
        "        memoria_actual = psutil.virtual_memory().percent\n",
        "        self.stats['memoria_maxima'] = max(self.stats['memoria_maxima'], memoria_actual)\n",
        "\n",
        "def test_sistema_ocr():\n",
        "    \"\"\"Prueba diagnóstica del sistema OCR completo\"\"\"\n",
        "    print(\"EJECUTANDO DIAGNÓSTICO DEL SISTEMA OCR...\")\n",
        "\n",
        "    print(\"\\n1. Probando configuración de Tesseract...\")\n",
        "    OCRProcessor.verificar_configuracion_tesseract()\n",
        "\n",
        "    print(\"\\n2. Probando OCR básico...\")\n",
        "    if OCRProcessor.test_ocr_simple():\n",
        "        print(\"   OCR básico funciona correctamente\")\n",
        "    else:\n",
        "        print(\"   OCR básico falla - revisar instalación de Tesseract\")\n",
        "        return False\n",
        "\n",
        "    print(\"\\n3. Probando conversión PDF...\")\n",
        "    try:\n",
        "        from PIL import Image, ImageDraw\n",
        "        img = Image.new('RGB', (500, 300), color='white')\n",
        "        draw = ImageDraw.Draw(img)\n",
        "\n",
        "        draw.text((50, 50), \"FACTURA DE PRUEBA\", fill='black')\n",
        "        draw.text((50, 80), \"NCF: E31000001234\", fill='black')\n",
        "        draw.text((50, 110), \"RNC Cliente: 123456789\", fill='black')\n",
        "        draw.text((50, 140), \"VALOR A PAGAR $ 1.500,00\", fill='black')\n",
        "        draw.text((50, 170), \"FECHA FACTURA: 14.05.2025\", fill='black')\n",
        "        draw.text((50, 200), \"CREDITO\", fill='black')\n",
        "\n",
        "        texto, diag = OCRProcessor.extraer_texto_con_diagnostico(img)\n",
        "        print(f\"   Diagnóstico: {diag}\")\n",
        "\n",
        "        if texto and any(word in texto.upper() for word in [\"FACTURA\", \"NCF\", \"E31\", \"VALOR\", \"RNC\"]):\n",
        "            print(\"   Conversión y OCR funcionan correctamente\")\n",
        "            print(f\"   Texto extraído: {texto[:100].replace(chr(10), ' ')}...\")\n",
        "            return True\n",
        "        else:\n",
        "            print(\"   OCR funciona pero no extrae texto esperado\")\n",
        "            print(f\"   Texto completo: {texto}\")\n",
        "            return False\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   Error en test de conversión: {e}\")\n",
        "        return False\n",
        "\n",
        "    print(\"\\nDIAGNÓSTICO COMPLETADO\")\n",
        "\n",
        "print(\"Clases OCR inicializadas\")"
      ],
      "metadata": {
        "id": "GmPz1vKlPovI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf4fdb5-82e3-4d2b-b128-71f47dc28637"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clases OCR inicializadas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Celda #3: Orquesta todo el proceso de OCR y guarda en Google Sheets**"
      ],
      "metadata": {
        "id": "mMTs__-p_YLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DocumentProcessor:\n",
        "    \"\"\"Procesador OCR con diagnóstico avanzado para resolver problemas\"\"\"\n",
        "\n",
        "    def __init__(self, drive_base_path: str, sheet_name: str, enable_debug: bool = False):\n",
        "        self.base_path = drive_base_path\n",
        "        self.input_path = os.path.join(self.base_path, \"Input_MVP\")\n",
        "        self.debug_path = os.path.join(self.base_path, \"Debug_Output\") if enable_debug else None\n",
        "        self.enable_debug = enable_debug\n",
        "\n",
        "        # Crear directorios necesarios\n",
        "        os.makedirs(self.input_path, exist_ok=True)\n",
        "        if self.enable_debug:\n",
        "            os.makedirs(self.debug_path, exist_ok=True)\n",
        "\n",
        "        # Inicializar monitor de rendimiento\n",
        "        self.performance_monitor = PerformanceMonitor()\n",
        "\n",
        "        # Configurar servicios de Google\n",
        "        self._setup_google_services(sheet_name)\n",
        "\n",
        "        # Inicializar manager de lotes\n",
        "        self.batch_manager = BatchSheetsManager(self.spreadsheet)\n",
        "\n",
        "        # Cache para registros existentes\n",
        "        self._load_existing_records_cache()\n",
        "\n",
        "        # Verificación diagnóstica del sistema\n",
        "        # self._diagnostic_system_check()\n",
        "\n",
        "    def _diagnostic_system_check(self):\n",
        "        \"\"\"Verificación diagnóstica del sistema OCR\"\"\"\n",
        "        print(\"\\nDIAGNÓSTICO DEL SISTEMA OCR:\")\n",
        "\n",
        "        # Verificar configuración de Tesseract primero\n",
        "        OCRProcessor.verificar_configuracion_tesseract()\n",
        "\n",
        "        if os.path.exists(self.input_path):\n",
        "            archivos = [f for f in os.listdir(self.input_path) if f.lower().endswith('.pdf')]\n",
        "            print(f\"   Archivos PDF encontrados: {len(archivos)}\")\n",
        "\n",
        "            if archivos:\n",
        "                archivo_prueba = archivos[0]\n",
        "                ruta_prueba = os.path.join(self.input_path, archivo_prueba)\n",
        "                print(f\"   Probando con archivo: {archivo_prueba}\")\n",
        "\n",
        "                texto, diagnosticos = OCRProcessor.procesar_pdf_con_diagnostico(ruta_prueba, dpi=200)\n",
        "\n",
        "                for diag in diagnosticos:\n",
        "                    print(f\"   {diag}\")\n",
        "\n",
        "                if texto and len(texto.strip()) > 10:\n",
        "                    print(f\"   Sistema OCR funcionando - extrajo {len(texto)} caracteres\")\n",
        "\n",
        "                    # Verificar si extrae contenido relevante de factura\n",
        "                    texto_upper = texto.upper()\n",
        "                    palabras_clave = [\"FACTURA\", \"NCF\", \"RNC\", \"VALOR\", \"TOTAL\", \"PAGAR\", \"FECHA\"]\n",
        "                    palabras_encontradas = [p for p in palabras_clave if p in texto_upper]\n",
        "\n",
        "                    if palabras_encontradas:\n",
        "                        print(f\"   Contenido relevante detectado: {', '.join(palabras_encontradas)}\")\n",
        "                    else:\n",
        "                        print(\"   Texto extraído pero sin palabras clave de factura\")\n",
        "\n",
        "                    if self.enable_debug:\n",
        "                        debug_file = os.path.join(self.debug_path, \"diagnostic_output.txt\")\n",
        "                        with open(debug_file, 'w', encoding='utf-8') as f:\n",
        "                            f.write(f\"DIAGNÓSTICO - {archivo_prueba}\\n\")\n",
        "                            f.write(\"=\" * 50 + \"\\n\")\n",
        "                            for diag in diagnosticos:\n",
        "                                f.write(f\"{diag}\\n\")\n",
        "                            f.write(f\"\\nPALABRAS CLAVE ENCONTRADAS: {', '.join(palabras_encontradas)}\\n\")\n",
        "                            f.write(\"\\nTEXTO EXTRAÍDO:\\n\")\n",
        "                            f.write(texto)\n",
        "                        print(f\"   Debug guardado en: {debug_file}\")\n",
        "                else:\n",
        "                    print(f\"   Sistema OCR con problemas - revisar instalaciones\")\n",
        "        else:\n",
        "            print(f\"   Carpeta no existe: {self.input_path}\")\n",
        "\n",
        "    def _setup_google_services(self, sheet_name: str):\n",
        "        \"\"\"Configuración de servicios Google\"\"\"\n",
        "        try:\n",
        "            print(\"Autenticando servicios de Google...\")\n",
        "            auth.authenticate_user()\n",
        "            creds, _ = default()\n",
        "\n",
        "            gc = gspread.authorize(creds)\n",
        "            self.spreadsheet = gc.open(sheet_name)\n",
        "            self.drive_service = build('drive', 'v3', credentials=creds)\n",
        "\n",
        "            self._ensure_sheets_exist()\n",
        "\n",
        "            print(\"Servicios Google configurados exitosamente\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error configurando servicios: {e}\")\n",
        "            raise e\n",
        "\n",
        "    def _ensure_sheets_exist(self):\n",
        "        \"\"\"Asegurar que las hojas necesarias existen\"\"\"\n",
        "        required_sheets = {\n",
        "            \"Metadata\": [\"nombre_archivo\", \"link_archivo_drive\", \"timestamp_proceso\",\n",
        "                        \"estado_ocr\", \"error\", \"campos_extraidos\", \"confianza_extraccion\", \"tiempo_procesamiento\"],\n",
        "            \"Facturas_Digitalizadas\": [\"ncf_factura\", \"cliente_rnc\", \"cliente_nombre\", \"fecha_emision\",\n",
        "                                     \"fecha_vencimiento\", \"tipo_pago\", \"valor_pagar\", \"vendedor\",\n",
        "                                     \"nombre_archivo\", \"link_archivo_drive\"]\n",
        "        }\n",
        "\n",
        "        for sheet_name, headers in required_sheets.items():\n",
        "            try:\n",
        "                self.spreadsheet.worksheet(sheet_name)\n",
        "            except:\n",
        "                print(f\"Creando hoja {sheet_name}...\")\n",
        "                new_sheet = self.spreadsheet.add_worksheet(sheet_name, 1000, len(headers))\n",
        "                new_sheet.append_row(headers)\n",
        "\n",
        "    def _load_existing_records_cache(self):\n",
        "        \"\"\"Cache de registros existentes\"\"\"\n",
        "        self.existing_records = {}\n",
        "        try:\n",
        "            metadata_sheet = self.spreadsheet.worksheet(\"Metadata\")\n",
        "            records = metadata_sheet.get_all_records()\n",
        "\n",
        "            for record in records:\n",
        "                filename = record.get('nombre_archivo', '')\n",
        "                if filename:\n",
        "                    self.existing_records[filename] = {\n",
        "                        'estado': record.get('estado_ocr', ''),\n",
        "                        'confianza': record.get('confianza_extraccion', ''),\n",
        "                        'tiempo': record.get('tiempo_procesamiento', 0)\n",
        "                    }\n",
        "\n",
        "            print(f\"Cache cargado: {len(self.existing_records)} registros existentes\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error cargando cache: {e}\")\n",
        "            self.existing_records = {}\n",
        "\n",
        "    def _should_skip_file(self, filename: str) -> bool:\n",
        "        \"\"\"Determina si debe saltar el archivo basado en cache\"\"\"\n",
        "        if filename not in self.existing_records:\n",
        "            return False\n",
        "\n",
        "        record = self.existing_records[filename]\n",
        "        estado = record.get('estado', '')\n",
        "        confianza = record.get('confianza', '')\n",
        "\n",
        "        # Saltar solo si es exitoso con alta confianza\n",
        "        return estado == \"Exitoso\" and confianza == \"Alta\"\n",
        "\n",
        "    def _get_drive_files_info(self) -> dict:\n",
        "        \"\"\"Obtener info de archivos de Drive con menos llamadas API\"\"\"\n",
        "        try:\n",
        "            folder_name = os.path.basename(self.input_path)\n",
        "            parent_folder_name = os.path.basename(os.path.dirname(self.input_path))\n",
        "\n",
        "            query = f\"name='{folder_name}' and mimeType='application/vnd.google-apps.folder' and trashed=false\"\n",
        "            response = self.drive_service.files().list(q=query, fields='files(id, name, parents)').execute()\n",
        "            folders = response.get('files', [])\n",
        "\n",
        "            if not folders:\n",
        "                return {}\n",
        "\n",
        "            folder_id = folders[0].get('id')\n",
        "\n",
        "            files_query = f\"'{folder_id}' in parents and trashed=false\"\n",
        "            files_response = self.drive_service.files().list(q=files_query, fields='files(id, name)').execute()\n",
        "            files = files_response.get('files', [])\n",
        "\n",
        "            print(f\"{len(files)} archivos encontrados en Drive\")\n",
        "            return {file.get('name'): file.get('id') for file in files}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error buscando archivos en Drive: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _extraer_datos(self, texto_completo: str, nombre_archivo: str, link_drive: str) -> Tuple[FacturaPrincipal, int, str]:\n",
        "        \"\"\"Extracción de datos con mínimas operaciones\"\"\"\n",
        "        inicio_extraccion = time.time()\n",
        "        factura = FacturaPrincipal(nombre_archivo=nombre_archivo, link_archivo_drive=link_drive)\n",
        "\n",
        "        texto_limpio = texto_completo.replace('\\n', ' ').replace('  ', ' ').strip()\n",
        "\n",
        "        campos_extraidos = 0\n",
        "\n",
        "        # Extraer campos críticos\n",
        "        ncf = PatternExtractor.extraer_campo(texto_limpio, 'ncf')\n",
        "        if ncf:\n",
        "            factura.ncf_factura = ncf\n",
        "            campos_extraidos += 1\n",
        "\n",
        "        rnc = PatternExtractor.extraer_campo(texto_limpio, 'rnc')\n",
        "        if rnc:\n",
        "            factura.cliente_rnc = rnc\n",
        "            campos_extraidos += 1\n",
        "\n",
        "        valor_raw = PatternExtractor.extraer_campo(texto_limpio, 'valor_pagar')\n",
        "        if valor_raw:\n",
        "            factura.valor_pagar = ValueNormalizer.normalizar_valor_monetario(valor_raw)\n",
        "            if factura.valor_pagar > 0:\n",
        "                campos_extraidos += 1\n",
        "\n",
        "        fecha_emision = PatternExtractor.extraer_campo(texto_limpio, 'fecha_emision')\n",
        "        if fecha_emision:\n",
        "            factura.fecha_emision = fecha_emision\n",
        "            campos_extraidos += 1\n",
        "\n",
        "        # Campos secundarios\n",
        "        tipo_pago = PatternExtractor.extraer_campo(texto_limpio, 'tipo_pago')\n",
        "        if tipo_pago:\n",
        "            factura.tipo_pago = tipo_pago\n",
        "            campos_extraidos += 1\n",
        "\n",
        "        nombre_cliente = PatternExtractor.extraer_campo(texto_limpio, 'nombre_cliente')\n",
        "        if nombre_cliente:\n",
        "            factura.cliente_nombre = nombre_cliente\n",
        "            campos_extraidos += 1\n",
        "\n",
        "        vendedor = PatternExtractor.extraer_campo(texto_limpio, 'vendedor')\n",
        "        if vendedor:\n",
        "            factura.vendedor = vendedor\n",
        "            campos_extraidos += 1\n",
        "\n",
        "        # Calcular fecha vencimiento\n",
        "        if factura.fecha_emision != \"No encontrado\" and factura.tipo_pago != \"No encontrado\":\n",
        "            factura.fecha_vencimiento = self._calcular_vencimiento(factura.fecha_emision, factura.tipo_pago)\n",
        "            if factura.fecha_vencimiento != \"No encontrado\":\n",
        "                campos_extraidos += 1\n",
        "\n",
        "        # Calcular confianza\n",
        "        campos_criticos = [factura.ncf_factura, factura.cliente_rnc, factura.valor_pagar, factura.fecha_emision]\n",
        "        campos_criticos_exitosos = sum(1 for campo in campos_criticos if campo != \"No encontrado\" and campo != 0.0)\n",
        "\n",
        "        if campos_criticos_exitosos >= 3:\n",
        "            confianza = \"Alta\"\n",
        "        elif campos_criticos_exitosos >= 2:\n",
        "            confianza = \"Media\"\n",
        "        else:\n",
        "            confianza = \"Baja\"\n",
        "\n",
        "        tiempo_extraccion = time.time() - inicio_extraccion\n",
        "\n",
        "        return factura, campos_extraidos, confianza\n",
        "\n",
        "    def _calcular_vencimiento(self, fecha_emision: str, tipo_pago: str) -> str:\n",
        "        \"\"\"Cálculo de vencimiento\"\"\"\n",
        "        try:\n",
        "            if tipo_pago.upper() == \"CONTADO\":\n",
        "                return fecha_emision\n",
        "            elif tipo_pago.upper() == \"CREDITO\":\n",
        "                fecha_base = datetime.strptime(fecha_emision, \"%d.%m.%Y\")\n",
        "                fecha_vencimiento = fecha_base + timedelta(days=30)\n",
        "                return fecha_vencimiento.strftime(\"%d.%m.%Y\")\n",
        "        except:\n",
        "            pass\n",
        "        return \"No encontrado\"\n",
        "\n",
        "    def _validar_factura(self, factura: FacturaPrincipal) -> Tuple[bool, str]:\n",
        "        \"\"\"Validación de factura\"\"\"\n",
        "        # Validación NCF\n",
        "        ncf_valido = (factura.ncf_factura != \"No encontrado\" and\n",
        "                     factura.ncf_factura.startswith('E31') and\n",
        "                     len(factura.ncf_factura) == 13)\n",
        "\n",
        "        # Validación RNC\n",
        "        rnc_limpio = re.sub(r'[-\\s]', '', factura.cliente_rnc) if factura.cliente_rnc != \"No encontrado\" else \"\"\n",
        "        rnc_valido = len(rnc_limpio) in [9, 11] and rnc_limpio.isdigit()\n",
        "\n",
        "        # Validación valor\n",
        "        valor_valido = factura.valor_pagar > 0\n",
        "\n",
        "        # Lógica de identificación\n",
        "        if ncf_valido and valor_valido:\n",
        "            return True, \"NCF_VALIDO\"\n",
        "        elif rnc_valido and valor_valido:\n",
        "            fecha_limpia = factura.fecha_emision.replace('.', '') if factura.fecha_emision != \"No encontrado\" else \"NOFECHA\"\n",
        "            factura.ncf_factura = f\"RNC_{rnc_limpio}_{fecha_limpia}\"\n",
        "            return True, \"RNC_ALTERNATIVO\"\n",
        "        else:\n",
        "            errores = []\n",
        "            if not ncf_valido and not rnc_valido:\n",
        "                errores.append(\"Sin identificador válido\")\n",
        "            if not valor_valido:\n",
        "                errores.append(f\"Valor inválido: {factura.valor_pagar}\")\n",
        "            return False, \" | \".join(errores)\n",
        "\n",
        "    def procesar_lote(self, archivos_lote: List[str], drive_files_info: dict):\n",
        "        \"\"\"Procesamiento de lote con máxima eficiencia y diagnóstico\"\"\"\n",
        "        print(f\"Procesando lote de {len(archivos_lote)} archivos...\")\n",
        "\n",
        "        archivos_procesados = 0\n",
        "        archivos_saltados = 0\n",
        "\n",
        "        for nombre_archivo in archivos_lote:\n",
        "            inicio_archivo = time.time()\n",
        "\n",
        "            if self._should_skip_file(nombre_archivo):\n",
        "                print(f\"Saltando: {nombre_archivo} (ya procesado exitosamente)\")\n",
        "                archivos_saltados += 1\n",
        "                continue\n",
        "\n",
        "            file_id = drive_files_info.get(nombre_archivo)\n",
        "            link_drive = f\"https://drive.google.com/file/d/{file_id}/view\" if file_id else \"No encontrado\"\n",
        "\n",
        "            print(f\"Procesando: {nombre_archivo}\")\n",
        "\n",
        "            try:\n",
        "                ruta_completa = os.path.join(self.input_path, nombre_archivo)\n",
        "\n",
        "                texto_completo, diagnosticos = OCRProcessor.procesar_pdf_con_diagnostico(ruta_completa, dpi=200)\n",
        "\n",
        "                if self.enable_debug:\n",
        "                    for diag in diagnosticos[-2:]:\n",
        "                        print(f\"   {diag}\")\n",
        "\n",
        "                if not texto_completo or not texto_completo.strip():\n",
        "                    error_msg = \"No se pudo extraer texto del PDF\"\n",
        "                    if diagnosticos:\n",
        "                        error_msg += f\" - {diagnosticos[-1]}\"\n",
        "                    raise Exception(error_msg)\n",
        "\n",
        "                if self.enable_debug:\n",
        "                    debug_file = os.path.join(self.debug_path, f\"{os.path.splitext(nombre_archivo)[0]}_ocr.txt\")\n",
        "                    with open(debug_file, 'w', encoding='utf-8') as f:\n",
        "                        f.write(f\"DIAGNÓSTICO - {nombre_archivo}\\n\")\n",
        "                        f.write(\"=\" * 50 + \"\\n\")\n",
        "                        for diag in diagnosticos:\n",
        "                            f.write(f\"{diag}\\n\")\n",
        "                        f.write(\"\\nTEXTO EXTRAÍDO:\\n\")\n",
        "                        f.write(texto_completo)\n",
        "\n",
        "                factura, campos_extraidos, confianza = self._extraer_datos(\n",
        "                    texto_completo, nombre_archivo, link_drive\n",
        "                )\n",
        "\n",
        "                es_valida, detalle = self._validar_factura(factura)\n",
        "\n",
        "                tiempo_archivo = time.time() - inicio_archivo\n",
        "\n",
        "                metadata_data = [\n",
        "                    nombre_archivo, link_drive, datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                    \"Exitoso\" if es_valida else \"Fallido\",\n",
        "                    \"\" if es_valida else detalle,\n",
        "                    campos_extraidos, confianza, round(tiempo_archivo, 2)\n",
        "                ]\n",
        "\n",
        "                if es_valida:\n",
        "                    factura_data = [\n",
        "                        factura.ncf_factura, factura.cliente_rnc, factura.cliente_nombre,\n",
        "                        factura.fecha_emision, factura.fecha_vencimiento, factura.tipo_pago,\n",
        "                        f\"${factura.valor_pagar:,.2f}\", factura.vendedor,\n",
        "                        nombre_archivo, link_drive\n",
        "                    ]\n",
        "                    self.batch_manager.add_factura(factura_data)\n",
        "                    print(f\"   Exitoso: {detalle} - ${factura.valor_pagar:,.2f} ({tiempo_archivo:.1f}s)\")\n",
        "                else:\n",
        "                    print(f\"   Fallido: {detalle} ({tiempo_archivo:.1f}s)\")\n",
        "\n",
        "                self.batch_manager.add_metadata(metadata_data)\n",
        "\n",
        "                if self.batch_manager.should_flush():\n",
        "                    self.batch_manager.flush_batch()\n",
        "\n",
        "                self.performance_monitor.record_file_processed(tiempo_archivo, es_valida)\n",
        "                archivos_procesados += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                tiempo_archivo = time.time() - inicio_archivo\n",
        "                error_msg = str(e)[:200]\n",
        "\n",
        "                metadata_data = [\n",
        "                    nombre_archivo, link_drive, datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                    \"Fallido\", error_msg, 0, \"Baja\", round(tiempo_archivo, 2)\n",
        "                ]\n",
        "                self.batch_manager.add_metadata(metadata_data)\n",
        "\n",
        "                print(f\"   Error: {nombre_archivo} - {error_msg} ({tiempo_archivo:.1f}s)\")\n",
        "                self.performance_monitor.record_file_processed(tiempo_archivo, False)\n",
        "                archivos_procesados += 1\n",
        "\n",
        "            if archivos_procesados % 5 == 0:\n",
        "                gc.collect()\n",
        "\n",
        "        self.batch_manager.flush_batch()\n",
        "\n",
        "        print(f\"Lote completado: {archivos_procesados} procesados, {archivos_saltados} saltados\")\n",
        "\n",
        "print(\"Procesador OCR inicializado\")"
      ],
      "metadata": {
        "id": "l0HWn2a6-RWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b481a65d-9e89-48b4-e02a-cd02e814d6da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesador OCR inicializado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Celda #4: Hace el despligue final del proceso**\n"
      ],
      "metadata": {
        "id": "XJoUZoupAJK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ejecutar_proceso_ocr(\n",
        "    nombre_base_de_datos: str = \"BaseDatos_Facturas\",\n",
        "    tamano_lote_inicial: int = 20,\n",
        "    pausa_entre_lotes_seg: int = 1,\n",
        "    enable_debug: bool = False,\n",
        "    adaptive_batching: bool = True\n",
        "):\n",
        "    \"\"\"Ejecutor principal\"\"\"\n",
        "\n",
        "    print(\"SISTEMA OCR INICIADO\")\n",
        "\n",
        "    metricas_globales = {\n",
        "        'inicio_proceso': time.time(),\n",
        "        'total_archivos_encontrados': 0,\n",
        "        'archivos_nuevos': 0,\n",
        "        'archivos_saltados': 0,\n",
        "        'archivos_reprocesados': 0,\n",
        "        'exitosos_ncf': 0,\n",
        "        'exitosos_rnc': 0,\n",
        "        'fallidos': 0,\n",
        "        'valor_total_extraido': 0.0,\n",
        "        'tiempo_ahorrado_cache': 0.0,\n",
        "        'lotes_procesados': 0,\n",
        "        'memoria_promedio': 0.0,\n",
        "        'velocidad_objetivo': 15.0\n",
        "    }\n",
        "\n",
        "    # Inicialización con diagnóstico\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        print(\"\\nMontando Google Drive...\")\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "        procesador = DocumentProcessor(\n",
        "            drive_base_path=\"/content/drive/MyDrive/OCR_Facturas\",\n",
        "            sheet_name=nombre_base_de_datos,\n",
        "            enable_debug=enable_debug\n",
        "        )\n",
        "\n",
        "        print(f\"Procesador inicializado (Debug: {'ON' if enable_debug else 'OFF'})\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error durante inicialización: {e}\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nANÁLISIS INICIAL\")\n",
        "\n",
        "    drive_files_info = procesador._get_drive_files_info()\n",
        "    archivos_locales = [f for f in os.listdir(procesador.input_path) if f.lower().endswith('.pdf')]\n",
        "\n",
        "    if not archivos_locales:\n",
        "        print(\"No se encontraron archivos PDF en la carpeta de entrada\")\n",
        "        return\n",
        "\n",
        "    metricas_globales['total_archivos_encontrados'] = len(archivos_locales)\n",
        "\n",
        "    # Análisis de cache\n",
        "    archivos_nuevos = []\n",
        "    archivos_saltados = []\n",
        "\n",
        "    for archivo in archivos_locales:\n",
        "        if procesador._should_skip_file(archivo):\n",
        "            archivos_saltados.append(archivo)\n",
        "            metricas_globales['archivos_saltados'] += 1\n",
        "            metricas_globales['tiempo_ahorrado_cache'] += 20\n",
        "        else:\n",
        "            archivos_nuevos.append(archivo)\n",
        "            metricas_globales['archivos_nuevos'] += 1\n",
        "\n",
        "    print(f\"   Total encontrados: {len(archivos_locales)}\")\n",
        "    print(f\"   Nuevos a procesar: {len(archivos_nuevos)}\")\n",
        "    print(f\"   Saltados (cache): {len(archivos_saltados)}\")\n",
        "    print(f\"   Tiempo ahorrado: {metricas_globales['tiempo_ahorrado_cache']/60:.1f} min\")\n",
        "\n",
        "    if not archivos_nuevos:\n",
        "        print(\"\\nTODOS LOS ARCHIVOS YA PROCESADOS EXITOSAMENTE\")\n",
        "        print(f\"Tiempo total ahorrado: {metricas_globales['tiempo_ahorrado_cache']/60:.1f} minutos\")\n",
        "        return\n",
        "\n",
        "    # Configuración de lotes adaptativos\n",
        "    tamano_lote_actual = tamano_lote_inicial\n",
        "    lotes = [archivos_nuevos[i:i + tamano_lote_actual] for i in range(0, len(archivos_nuevos), tamano_lote_actual)]\n",
        "\n",
        "    print(f\"\\nCONFIGURACIÓN DE PROCESAMIENTO\")\n",
        "    print(f\"   Total lotes: {len(lotes)}\")\n",
        "    print(f\"   Tamaño lote inicial: {tamano_lote_actual}\")\n",
        "    print(f\"   Pausa entre lotes: {pausa_entre_lotes_seg}s\")\n",
        "    print(f\"   Ajuste automático: {'ON' if adaptive_batching else 'OFF'}\")\n",
        "    print(f\"   Debug mode: {'ON' if enable_debug else 'OFF'}\")\n",
        "\n",
        "    print(f\"\\n\" + \"=\" * 80)\n",
        "    print(f\"INICIANDO PROCESAMIENTO\")\n",
        "    print(f\"=\" * 80)\n",
        "\n",
        "    tiempo_inicio_procesamiento = time.time()\n",
        "\n",
        "    for i, lote_actual in enumerate(lotes):\n",
        "        tiempo_inicio_lote = time.time()\n",
        "        metricas_globales['lotes_procesados'] += 1\n",
        "\n",
        "        print(f\"\\nLOTE #{i+1}/{len(lotes)} - {len(lote_actual)} archivos\")\n",
        "        print(f\"   Progreso global: {(i/len(lotes))*100:.1f}%\")\n",
        "\n",
        "        # Monitoreo de memoria pre-lote\n",
        "        memoria_pre = psutil.virtual_memory().percent\n",
        "        if memoria_pre > 80:\n",
        "            print(f\"   Liberando memoria (uso: {memoria_pre:.1f}%)...\")\n",
        "            gc.collect()\n",
        "            memoria_post = psutil.virtual_memory().percent\n",
        "            print(f\"   Memoria optimizada: {memoria_pre:.1f}% -> {memoria_post:.1f}%\")\n",
        "\n",
        "        # Procesar lote con diagnóstico\n",
        "        procesador.procesar_lote(lote_actual, drive_files_info)\n",
        "\n",
        "        tiempo_lote = time.time() - tiempo_inicio_lote\n",
        "        velocidad_lote = len(lote_actual) / (tiempo_lote / 60)\n",
        "\n",
        "        print(f\"   Tiempo lote: {tiempo_lote:.1f}s\")\n",
        "        print(f\"   Velocidad: {velocidad_lote:.1f} archivos/min\")\n",
        "\n",
        "        # Ajuste adaptativo de lotes\n",
        "        if adaptive_batching and i < len(lotes) - 1:\n",
        "            if velocidad_lote > metricas_globales['velocidad_objetivo'] * 1.2:\n",
        "                nuevo_tamano = min(tamano_lote_actual + 5, 30)\n",
        "                if nuevo_tamano != tamano_lote_actual:\n",
        "                    print(f\"   Ajuste: Incrementando lote {tamano_lote_actual} -> {nuevo_tamano}\")\n",
        "                    tamano_lote_actual = nuevo_tamano\n",
        "            elif velocidad_lote < metricas_globales['velocidad_objetivo'] * 0.8:\n",
        "                nuevo_tamano = max(tamano_lote_actual - 3, 5)\n",
        "                if nuevo_tamano != tamano_lote_actual:\n",
        "                    print(f\"   Ajuste: Reduciendo lote {tamano_lote_actual} -> {nuevo_tamano}\")\n",
        "                    tamano_lote_actual = nuevo_tamano\n",
        "\n",
        "        # Pausa entre lotes\n",
        "        if i < len(lotes) - 1:\n",
        "            print(f\"   Pausa: {pausa_entre_lotes_seg}s...\")\n",
        "            time.sleep(pausa_entre_lotes_seg)\n",
        "\n",
        "    # Información de debug\n",
        "    if enable_debug:\n",
        "        print(f\"\\nARCHIVOS DE DEBUG GENERADOS:\")\n",
        "        if procesador.debug_path and os.path.exists(procesador.debug_path):\n",
        "            debug_files = [f for f in os.listdir(procesador.debug_path) if f.endswith('.txt')]\n",
        "            print(f\"   Ubicación: {procesador.debug_path}\")\n",
        "            print(f\"   Archivos generados: {len(debug_files)}\")\n",
        "            if debug_files:\n",
        "                print(f\"   Revisar estos archivos para análisis detallado de problemas\")\n",
        "                for i, debug_file in enumerate(debug_files[:3]):\n",
        "                    print(f\"      {i+1}. {debug_file}\")\n",
        "                if len(debug_files) > 3:\n",
        "                    print(f\"      ... y {len(debug_files) - 3} más\")\n",
        "\n",
        "# EJECUTAR PROCESO\n",
        "print(\"Iniciando proceso OCR completo...\")\n",
        "\n",
        "metricas_resultado = ejecutar_proceso_ocr(\n",
        "    nombre_base_de_datos=\"BaseDatos_Facturas\",\n",
        "    tamano_lote_inicial=20,\n",
        "    pausa_entre_lotes_seg=1,\n",
        "    enable_debug=False,\n",
        "    adaptive_batching=True\n",
        ")\n",
        "\n",
        "print(\"\\nPROCESO OCR FINALIZADO\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6RCPhxf2Bm-",
        "outputId": "a044800d-e78a-4fd3-e8c8-18c115875dc9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando proceso OCR completo...\n",
            "SISTEMA OCR INICIADO\n",
            "\n",
            "Montando Google Drive...\n",
            "Mounted at /content/drive\n",
            "Autenticando servicios de Google...\n",
            "Servicios Google configurados exitosamente\n",
            "Cache cargado: 0 registros existentes\n",
            "Procesador inicializado (Debug: OFF)\n",
            "\n",
            "ANÁLISIS INICIAL\n",
            "6 archivos encontrados en Drive\n",
            "   Total encontrados: 6\n",
            "   Nuevos a procesar: 6\n",
            "   Saltados (cache): 0\n",
            "   Tiempo ahorrado: 0.0 min\n",
            "\n",
            "CONFIGURACIÓN DE PROCESAMIENTO\n",
            "   Total lotes: 1\n",
            "   Tamaño lote inicial: 20\n",
            "   Pausa entre lotes: 1s\n",
            "   Ajuste automático: ON\n",
            "   Debug mode: OFF\n",
            "\n",
            "================================================================================\n",
            "INICIANDO PROCESAMIENTO\n",
            "================================================================================\n",
            "\n",
            "LOTE #1/1 - 6 archivos\n",
            "   Progreso global: 0.0%\n",
            "Procesando lote de 6 archivos...\n",
            "Procesando: Registro_Files__33802265.Anexo.135430.pdf\n",
            "   Exitoso: NCF_VALIDO - $36,590.57 (25.4s)\n",
            "Procesando: Registro_Files__33802279.Anexo.141147.pdf\n",
            "   Exitoso: RNC_ALTERNATIVO - $91,376.37 (4.8s)\n",
            "Procesando: Registro_Files__30802262.Anexo.135014.pdf\n",
            "   Exitoso: NCF_VALIDO - $28,164.72 (13.7s)\n",
            "Procesando: Registro_Files__33802283.Anexo.141538.pdf\n",
            "   Exitoso: NCF_VALIDO - $12,174.72 (7.9s)\n",
            "Procesando: Registro_Files__33802276.Anexo.140859.pdf\n",
            "   Exitoso: NCF_VALIDO - $29,008.88 (4.5s)\n",
            "Procesando: Registro_Files__33802266.Anexo.135532.pdf\n",
            "   Exitoso: NCF_VALIDO - $12,849.09 (8.3s)\n",
            "Lote enviado: 6 facturas\n",
            "Lote enviado: 6 metadata\n",
            "Lote completado: 6 procesados, 0 saltados\n",
            "   Tiempo lote: 65.3s\n",
            "   Velocidad: 5.5 archivos/min\n",
            "\n",
            "PROCESO OCR FINALIZADO\n"
          ]
        }
      ]
    }
  ]
}